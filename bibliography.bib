% Here are some examples of different sources to reference.



@article{karkhanis2023complete,
  title={Complete Review of 360 Degree Cameras: A Comprehensive White Paper},
  author={Karkhanis, Kaustubh},
  journal={Available at SSRN 4501119},
  year={2023}
}
@misc{Thebest360camerasin2024,
   title = {The best 360 cameras in 2024 | Digital Camera World},
   url = {https://www.digitalcameraworld.com/buying-guides/best-360-cameras},
}
@misc{PhotogrammetryWorkflowusingaDSLRCamera,
   title = {Photogrammetry Workflow using a DSLR Camera | Scholars' Lab},
   url = {https://scholarslab.lib.virginia.edu/blog/documentation-photogrammetry//},
}
@inproceedings{samosir2020comparison,
  title={Comparison of Smartphone and DSLR Use in Photogrammetry},
  author={Samosir, Ferdian Sahala and Riyadi, Slamet},
  booktitle={International Conference on Aesthetics and the Sciences of Art},
  year={2020},
  organization={Bandung Institute of Technology}
}
@article{Jasińska2023,
   author = {Aleksandra Jasińska and Krystian Pyka and Elżbieta Pastucha and Henrik Skov Midtiby},
   doi = {10.3390/s23020728},
   issn = {14248220},
   issue = {2},
   journal = {Sensors},
   keywords = {3D reconstruction,camera calibration,photogrammetry,smartphone,structure from motion},
   month = {1},
   publisher = {MDPI},
   title = {A Simple Way to Reduce 3D Model Deformation in Smartphone Photogrammetry},
   volume = {23},
   year = {2023},
}
@article{raj2020survey,
  title={A survey on LiDAR scanning mechanisms},
  author={Raj, Thinal and Hanim Hashim, Fazida and Baseri Huddin, Aqilah and Ibrahim, Mohd Faisal and Hussain, Aini},
  journal={Electronics},
  volume={9},
  number={5},
  pages={741},
  year={2020},
  publisher={MDPI}
}
@inproceedings{robin2014making,
  title={Making a difference: examples of the use of repeat LiDAR datasets to guide river management decisions following extreme floods},
  author={Robin, Grove James and Jacky, Croke and Chris, Thompson},
  booktitle={7th Australian Stream Management Conference},
  pages={232},
  year={2014}
}
@article{eitel2016beyond,
  title={Beyond 3-D: The new spectrum of lidar applications for earth and ecological sciences},
  author={Eitel, Jan UH and H{\"o}fle, Bernhard and Vierling, Lee A and Abell{\'a}n, Antonio and Asner, Gregory P and Deems, Jeffrey S and Glennie, Craig L and Joerg, Philip C and LeWinter, Adam L and Magney, Troy S and others},
  journal={Remote Sensing of Environment},
  volume={186},
  pages={372--392},
  year={2016},
  publisher={Elsevier}
}
@article{FundamentalsofLidarRemoteSensing,
   title = {Lecture 07. Fundamentals of Lidar Remote Sensing (5) "Basic Lidar Architecture"},
}
@article{PhysicalPictureofLidarEquation,
   title = {Physical Picture of Lidar Equation},
}
@article{thrun2002probabilistic,
  title={Probabilistic robotics},
  author={Thrun, Sebastian},
  journal={Communications of the ACM},
  volume={45},
  number={3},
  pages={52--57},
  year={2002},
  publisher={ACM New York, NY, USA}
}
@article{Taheri2021,
   author = {Hamid Taheri and Zhao Chun Xia},
   doi = {https://doi.org/10.1016/j.engappai.2020.104032},
   issn = {0952-1976},
   journal = {Engineering Applications of Artificial Intelligence},
   keywords = {Intelligent agent,Intelligent robots,SLAM algorithms,SLAM history,Simultaneous localization and mapping},
   pages = {104032},
   title = {SLAM; definition and evolution},
   volume = {97},
   url = {https://www.sciencedirect.com/science/article/pii/S0952197620303092},
   year = {2021},
}
@inproceedings{li2016real,
  title={Real-time simultaneous localization and mapping for uav: A survey},
  author={Li, Jiaxin and Bi, Yingcai and Lan, Menglu and Qin, Hailong and Shan, Mo and Lin, Feng and Chen, Ben M},
  booktitle={Proc. of International micro air vehicle competition and conference},
  volume={2016},
  pages={237},
  year={2016}
}
@inproceedings{klein2007parallel,
  title={Parallel tracking and mapping for small AR workspaces},
  author={Klein, Georg and Murray, David},
  booktitle={2007 6th IEEE and ACM international symposium on mixed and augmented reality},
  pages={225--234},
  year={2007},
  organization={IEEE}
}
@article{cadena2016past,
  title={Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age},
  author={Cadena, Cesar and Carlone, Luca and Carrillo, Henry and Latif, Yasir and Scaramuzza, Davide and Neira, Jos{\'e} and Reid, Ian and Leonard, John J},
  journal={IEEE Transactions on robotics},
  volume={32},
  number={6},
  pages={1309--1332},
  year={2016},
  publisher={IEEE}
}
@inproceedings{yavuz2009simultaneous,
  title={Simultaneous localization and mapping using Extended Kalman Filter},
  author={Yavuz, Sirma and Kurt, Zeyneb and Bicer, M Serdar},
  booktitle={2009 IEEE 17th Signal Processing and Communications Applications Conference},
  pages={700--703},
  year={2009},
  organization={IEEE}
}
@inproceedings{julier2001counter,
  title={A counter example to the theory of simultaneous localization and map building},
  author={Julier, Simon J and Uhlmann, Jeffrey K},
  booktitle={Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No. 01CH37164)},
  volume={4},
  pages={4238--4243},
  year={2001},
  organization={IEEE}
}
@book{leonard2012directed,
  title={Directed sonar sensing for mobile robot navigation},
  author={Leonard, John J and Durrant-Whyte, Hugh F},
  volume={175},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@inproceedings{chatila1985position,
  title={Position referencing and consistent world modeling for mobile robots},
  author={Chatila, Raja and Laumond, J},
  booktitle={Proceedings. 1985 IEEE International Conference on Robotics and Automation},
  volume={2},
  pages={138--145},
  year={1985},
  organization={IEEE}
}
@article{durrant2006simultaneous,
  title={Simultaneous localization and mapping: part I},
  author={Durrant-Whyte, Hugh and Bailey, Tim},
  journal={IEEE robotics \& automation magazine},
  volume={13},
  number={2},
  pages={99--110},
  year={2006},
  publisher={IEEE}
}
@article{bailey2006simultaneous,
  title={Simultaneous localization and mapping (SLAM): Part II},
  author={Bailey, Tim and Durrant-Whyte, Hugh},
  journal={IEEE robotics \& automation magazine},
  volume={13},
  number={3},
  pages={108--117},
  year={2006},
  publisher={IEEE}
}
@article{stachniss2016simultaneous,
  title={Simultaneous localization and mapping},
  author={Stachniss, Cyrill and Leonard, John J and Thrun, Sebastian},
  journal={Springer handbook of robotics},
  pages={1153--1176},
  year={2016},
  publisher={Springer}
}
@article{aulinas2008slam,
  title={The SLAM problem: a survey},
  author={Aulinas, Josep and Petillot, Yvan and Salvi, Joaquim and Llad{\'o}, Xavier},
  journal={Artificial Intelligence Research and Development},
  pages={363--371},
  year={2008},
  publisher={IOS Press}
}
@article{billinghurst2015survey,
  title={A survey of augmented reality},
  author={Billinghurst, Mark and Clark, Adrian and Lee, Gun and others},
  journal={Foundations and Trends{\textregistered} in Human--Computer Interaction},
  volume={8},
  number={2-3},
  pages={73--272},
  year={2015},
  publisher={Now Publishers, Inc.}
}
@article{Taketomi2017,
   author = {Takafumi Taketomi and Hideaki Uchiyama and Sei Ikeda},
   doi = {10.1186/s41074-017-0027-2},
   issn = {1882-6695},
   issue = {1},
   journal = {IPSJ Transactions on Computer Vision and Applications},
   pages = {16},
   title = {Visual SLAM algorithms: a survey from 2010 to 2016},
   volume = {9},
   url = {https://doi.org/10.1186/s41074-017-0027-2},
   year = {2017},
}
@inproceedings{martin2021nerf,
  title={Nerf in the wild: Neural radiance fields for unconstrained photo collections},
  author={Martin-Brualla, Ricardo and Radwan, Noha and Sajjadi, Mehdi SM and Barron, Jonathan T and Dosovitskiy, Alexey and Duckworth, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7210--7219},
  year={ 2021}
}
@book{shum2008image,
  title={Image-based rendering},
  author={Shum, Heung-Yeung and Chan, Shing-Chow and Kang, Sing Bing},
  year={2008},
  publisher={Springer Science \& Business Media}
}
@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@misc{defenseadvancement,
   title = {US Navy Tests New Applications for LiDAR Models in Battle Damage Assessment - Defense Advancement},
   url = {https://www.defenseadvancement.com/news/us-navy-tests-new-applications-for-lidar-models-in-battle-damage-assessment/},
}
@misc{LidarSolutionforship,
   title = {LiDAR Solutions for the Shipping Industry},
   url = {https://www.outsight.ai/insights/lidar-solutions-for-the-shipping-industry},
}
@article{deems2013lidar,
  title={Lidar measurement of snow depth: a review},
  author={Deems, Jeffrey S and Painter, Thomas H and Finnegan, David C},
  journal={Journal of Glaciology},
  volume={59},
  number={215},
  pages={467--479},
  year={2013},
  publisher={Cambridge University Press}
}
@article{aijazi2016detecting,
  title={Detecting and analyzing corrosion spots on the hull of large marine vessels using colored 3D lidar point clouds},
  author={Aijazi, AK and Malaterre, L and Tazir, ML and Trassoudaine, L and Checchin, P},
  journal={ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume={3},
  pages={153--160},
  year={2016},
  publisher={Copernicus Publications G{\"o}ttingen, Germany}
}
@article{yu2023techniques,
  title={Techniques and challenges of image segmentation: A review},
  author={Yu, Ying and Wang, Chunping and Fu, Qiang and Kou, Renke and Huang, Fuyu and Yang, Boxiong and Yang, Tingting and Gao, Mingliang},
  journal={Electronics},
  volume={12},
  number={5},
  pages={1199},
  year={2023},
  publisher={MDPI}
}
@article{kabiraj2023number,
  title={Number plate recognition from enhanced super-resolution using generative adversarial network},
  author={Kabiraj, Anwesh and Pal, Debojyoti and Ganguly, Debayan and Chatterjee, Kingshuk and Roy, Sudipta},
  journal={Multimedia Tools and Applications},
  volume={82},
  number={9},
  pages={13837--13853},
  year={2023},
  publisher={Springer}
}
@article{jin2020deep,
  title={Deep facial diagnosis: deep transfer learning from face recognition to facial diagnosis},
  author={Jin, Bo and Cruz, Leandro and Gon{\c{c}}alves, Nuno},
  journal={IEEE Access},
  volume={8},
  pages={123649--123661},
  year={2020},
  publisher={IEEE}
}
@inproceedings{zhao2021voxelembed,
  title={VoxelEmbed: 3D instance segmentation and tracking with voxel embedding based deep learning},
  author={Zhao, Mengyang and Liu, Quan and Jha, Aadarsh and Deng, Ruining and Yao, Tianyuan and Mahadevan-Jansen, Anita and Tyska, Matthew J and Millis, Bryan A and Huo, Yuankai},
  booktitle={Machine Learning in Medical Imaging: 12th International Workshop, MLMI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings 12},
  pages={437--446},
  year={2021},
  organization={Springer}
}
@inproceedings{yao2021compound,
  title={Compound figure separation of biomedical images with side loss},
  author={Yao, Tianyuan and Qu, Chang and Liu, Quan and Deng, Ruining and Tian, Yuanhan and Xu, Jiachen and Jha, Aadarsh and Bao, Shunxing and Zhao, Mengyang and Fogo, Agnes B and others},
  booktitle={Deep Generative Models, and Data Augmentation, Labelling, and Imperfections: First Workshop, DGM4MICCAI 2021, and First Workshop, DALI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, October 1, 2021, Proceedings 1},
  pages={173--183},
  year={2021},
  organization={Springer}
}
@article{wang2022comprehensive,
  title={A comprehensive review of modern object segmentation approaches},
  author={Wang, Yuanbo and Ahsan, Unaiza and Li, Hanyan and Hagen, Matthew and others},
  journal={Foundations and Trends{\textregistered} in Computer Graphics and Vision},
  volume={13},
  number={2-3},
  pages={111--283},
  year={2022},
  publisher={Now Publishers, Inc.}
}
@inproceedings{liu20173dcnn,
  title={3DCNN-DQN-RNN: A deep reinforcement learning framework for semantic parsing of large-scale 3D point clouds},
  author={Liu, Fangyu and Li, Shuaipeng and Zhang, Liqiang and Zhou, Chenghu and Ye, Rongtian and Wang, Yuebin and Lu, Jiwen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5678--5687},
  year={2017}
}
@inproceedings{nguyen20133d,
  title={3D point cloud segmentation: A survey},
  author={Nguyen, Anh and Le, Bac},
  booktitle={2013 6th IEEE conference on robotics, automation and mechatronics (RAM)},
  pages={225--230},
  year={2013},
  organization={IEEE}
}
@incollection{hurtado2022semantic,
  title={Semantic scene segmentation for robotics},
  author={Hurtado, Juana Valeria and Valada, Abhinav},
  booktitle={Deep learning for robot perception and cognition},
  pages={279--311},
  year={2022},
  publisher={Elsevier}
}
@article{premebida2018intelligent,
  title={Intelligent robotic perception systems},
  author={Premebida, Cristiano and Ambrus, Rares and Marton, Zoltan-Csaba},
  journal={Applications of mobile robots},
  pages={111--127},
  year={2018},
  publisher={IntechOpen London, UK}
}
@article{valada2020self,
  title={Self-supervised model adaptation for multimodal semantic segmentation},
  author={Valada, Abhinav and Mohan, Rohit and Burgard, Wolfram},
  journal={International Journal of Computer Vision},
  volume={128},
  number={5},
  pages={1239--1285},
  year={2020},
  publisher={Springer}
}
@inproceedings{avidan1997novel,
  title={Novel view synthesis in tensor space},
  author={Avidan, Shai and Shashua, Amnon},
  booktitle={Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={1034--1040},
  year={1997},
  organization={IEEE}
}
@article{kerbl20233d,
  title={3d gaussian splatting for real-time radiance field rendering},
  author={Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
  journal={ACM Transactions on Graphics},
  volume={42},
  number={4},
  pages={1--14},
  year={2023},
  publisher={ACM}
}

@incollection{gortler2023lumigraph,
  title={The lumigraph},
  author={Gortler, Steven J and Grzeszczuk, Radek and Szeliski, Richard and Cohen, Michael F},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={453--464},
  year={2023}
}
@inproceedings{buehler2001unstructured,
  title={Unstructured lumigraph rendering},
  author={Buehler, Chris and Bosse, Michael and McMillan, Leonard and Gortler, Steven and Cohen, Michael},
  booktitle={Proceedings of the 28th annual conference on Computer graphics and interactive techniques},
  pages={425--432},
  year={2001}
}
@incollection{snavely2006photo,
  title={Photo tourism: exploring photo collections in 3D},
  author={Snavely, Noah and Seitz, Steven M and Szeliski, Richard},
  booktitle={ACM siggraph 2006 papers},
  pages={835--846},
  year={2006}
}
@inproceedings{goesele2007multi,
  title={Multi-view stereo for community photo collections},
  author={Goesele, Michael and Snavely, Noah and Curless, Brian and Hoppe, Hugues and Seitz, Steven M},
  booktitle={2007 IEEE 11th International Conference on Computer Vision},
  pages={1--8},
  year={2007},
  organization={IEEE}
}

@inproceedings{chen2022tensorf,
  title={Tensorf: Tensorial radiance fields},
  author={Chen, Anpei and Xu, Zexiang and Geiger, Andreas and Yu, Jingyi and Su, Hao},
  booktitle={European Conference on Computer Vision},
  pages={333--350},
  year={2022},
  organization={Springer}
}
@inproceedings{garbin2021fastnerf,
  title={Fastnerf: High-fidelity neural rendering at 200fps},
  author={Garbin, Stephan J and Kowalski, Marek and Johnson, Matthew and Shotton, Jamie and Valentin, Julien},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={14346--14355},
  year={2021}
}
@inproceedings{reiser2021kilonerf,
  title={Kilonerf: Speeding up neural radiance fields with thousands of tiny mlps},
  author={Reiser, Christian and Peng, Songyou and Liao, Yiyi and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={14335--14345},
  year={2021}
}
@inproceedings{takikawa2021neural,
  title={Neural geometric level of detail: Real-time rendering with implicit 3d shapes},
  author={Takikawa, Towaki and Litalien, Joey and Yin, Kangxue and Kreis, Karsten and Loop, Charles and Nowrouzezahrai, Derek and Jacobson, Alec and McGuire, Morgan and Fidler, Sanja},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11358--11367},
  year={2021}
}
@inproceedings{barron2022mip,
  title={Mip-nerf 360: Unbounded anti-aliased neural radiance fields},
  author={Barron, Jonathan T and Mildenhall, Ben and Verbin, Dor and Srinivasan, Pratul P and Hedman, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5470--5479},
  year={2022}
}
@article{muller2022instant,
  title={Instant neural graphics primitives with a multiresolution hash encoding},
  author={M{\"u}ller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  journal={ACM transactions on graphics (TOG)},
  volume={41},
  number={4},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA}
}
@inproceedings{henzler2019escaping,
  title={Escaping plato's cave: 3d shape from adversarial rendering},
  author={Henzler, Philipp and Mitra, Niloy J and Ritschel, Tobias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9984--9993},
  year={2019}
}
@inproceedings{sitzmann2019deepvoxels,
  title={Deepvoxels: Learning persistent 3d feature embeddings},
  author={Sitzmann, Vincent and Thies, Justus and Heide, Felix and Nie{\ss}ner, Matthias and Wetzstein, Gordon and Zollhofer, Michael},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2437--2446},
  year={2019}
}
@inproceedings{pfister2000surfels,
  title={Surfels: Surface elements as rendering primitives},
  author={Pfister, Hanspeter and Zwicker, Matthias and Van Baar, Jeroen and Gross, Markus},
  booktitle={Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
  pages={335--342},
  year={2000}
}
@inproceedings{wiles2020synsin,
  title={Synsin: End-to-end view synthesis from a single image},
  author={Wiles, Olivia and Gkioxari, Georgia and Szeliski, Richard and Johnson, Justin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7467--7477},
  year={2020}
}
@article{chen2024survey,
  title={A survey on 3d gaussian splatting},
  author={Chen, Guikun and Wang, Wenguan},
  journal={arXiv preprint arXiv:2401.03890},
  year={2024}
}
@article{kalkofen2008comprehensible,
  title={Comprehensible visualization for augmented reality},
  author={Kalkofen, Denis and Mendez, Erick and Schmalstieg, Dieter},
  journal={IEEE transactions on visualization and computer graphics},
  volume={15},
  number={2},
  pages={193--204},
  year={2008},
  publisher={IEEE}
}
@article{patney2016towards,
  title={Towards foveated rendering for gaze-tracked virtual reality},
  author={Patney, Anjul and Salvi, Marco and Kim, Joohwan and Kaplanyan, Anton and Wyman, Chris and Benty, Nir and Luebke, David and Lefohn, Aaron},
  journal={ACM Transactions on Graphics (TOG)},
  volume={35},
  number={6},
  pages={1--12},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@article{albert2017latency,
  title={Latency requirements for foveated rendering in virtual reality},
  author={Albert, Rachel and Patney, Anjul and Luebke, David and Kim, Joohwan},
  journal={ACM Transactions on Applied Perception (TAP)},
  volume={14},
  number={4},
  pages={1--13},
  year={2017},
  publisher={ACM New York, NY, USA}
}
@inproceedings{chabra2020deep,
  title={Deep local shapes: Learning local sdf priors for detailed 3d reconstruction},
  author={Chabra, Rohan and Lenssen, Jan E and Ilg, Eddy and Schmidt, Tanner and Straub, Julian and Lovegrove, Steven and Newcombe, Richard},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIX 16},
  pages={608--625},
  year={2020},
  organization={Springer}
}
@inproceedings{wang2021learning,
  title={Learning indoor inverse rendering with 3d spatially-varying lighting},
  author={Wang, Zian and Philion, Jonah and Fidler, Sanja and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12538--12547},
  year={2021}
}
@article{Favi2018,
   abstract = {Maritime vessels are complex products with long service life and great costs of building, manning, operating, maintaining and repairing. The paper aims to introduce a specific life cycle model and related metrics in shipbuilding design, supporting decision-making processes of material selection, manufacturing/assembly practices, maintenance, use, etc. The model provides a common structure for life cycle assessment (LCA) and life cycle cost analysis (LCCA) including the way to retrieve and to collect necessary data for the analysis starting from the available project documentation and design models. Different design configurations (materials, welding methods, etc.) for hull and hatches of a luxury yacht have been analysed using the proposed model.},
   author = {Claudio Favi and Michele Germani and Federico Campi and Marco Mandolini and Steve Manieri and Marco Marconi and Alessio Vita},
   doi = {https://doi.org/10.1016/j.procir.2017.11.071},
   issn = {2212-8271},
   journal = {Procedia CIRP},
   keywords = {LCA,LCCA,design,maritime vessels,shipbuilding},
   note = {25th CIRP Life Cycle Engineering (LCE) Conference, 30 April – 2 May 2018, Copenhagen, Denmark},
   pages = {523-528},
   title = {Life Cycle Model and Metrics in Shipbuilding: How to Use them in the Preliminary Design Phases},
   volume = {69},
   url = {https://www.sciencedirect.com/science/article/pii/S2212827117308478},
   year = {2018},
}
@misc{Thedesignphase,
   title = {The Design Phase | Shipbuilding » SSI},
   url = {https://www.ssi-corporate.com/shipbuilding-solutions/design/},
}
@misc{Thebuildphase,
   title = {The Build Phase | Shipbuilding » SSI},
   url = {https://www.ssi-corporate.com/shipbuilding-solutions/build/},
}
@misc{LaserscanSSI,
   title = {Laser Scanning Case Study » SSI},
   url = {https://www.ssi-corporate.com/content/laser-scanning/},
}
@article{Stavroulakis2022,
   abstract = {Shipping is pivotal for global commerce, yet its externalities are not yet fully set into context, especially with reference to environmental impact. Shipping is a practise developed from the dawn of history. Its manifestation requires the introduction of relevant supporting industries as well, such as port, cargo, and logistics operations. The holistic shipping system has been growing with its main parameter pertaining to accounting cost minimisation. Yet, the shipping ecosystem has been able to exacerbate environmental, social, and health costs that in the end may prove that shipping, in the way that it is conducted, may not be as profitable as it may seem.},
   author = {Peter J Stavroulakis and Stratos Papadimitriou},
   doi = {10.1186/s41072-022-00116-7},
   issn = {2364-4575},
   issue = {1},
   journal = {Journal of Shipping and Trade},
   pages = {14},
   title = {Total cost of ownership in shipping: a framework for sustainability},
   volume = {7},
   url = {https://doi.org/10.1186/s41072-022-00116-7},
   year = {2022},
}
@misc{QooCam8K,
   title = {QooCam 8K | 8K Camera | 8K 360 Camera - Kandao Tech},
   url = {https://www.kandaovr.com/qoocam-8k/},
}
@misc{QooCam8KSPEC,
   title = {QooCam 8K Tech Spec - Kandao Tech},
   url = {https://www.kandaovr.com/qoocam-8k/tech-spec/},
}
@misc{ApertureScale,
   title = {Understanding Aperture in 5 Easy Steps},
   url = {https://www.photographytalk.com/photography-articles/4899-understanding-aperture-in-5-easy-steps},
}
@misc{lens,
   title = {What does an 'f/2.0 lens' mean? - Quora},
   url = {https://www.quora.com/What-does-an-f-2-0-lens-mean},
}
@misc{FOV,
   title = {What is field of view (FOV)?},
   url = {https://www.techtarget.com/whatis/definition/field-of-view-FOV},
}
@misc{Fov,
   title = {Learn | Field of View & Angular Field of View | Teledyne Princeton Instruments},
   url = {https://www.princetoninstruments.com/learn/camera-fundamentals/field-of-view-and-angular-field-of-view},
}

@misc{10Bit,
   title = {Bit},
   url = {https://fujifilm-x.com/en-us/series/the-filmmakers-handbook/8-bit-or-10-bit-video-color-explained/},
}
@misc{ADAPA360,
   title = {Adapa360},
   url = {https://adapa360.com/},
}
@misc{3DScan,
   title = {3D Scan Piping For Ships (And Why It Helps) - Centerline Design GmbH},
   url = {https://centerlinedesign.de/en/3d-scan-blog/3d-scan-piping-ships/},
}
@article{AVEVAE3D,
   abstract = {The most advanced 3D design solution for accurate and clash-free hull and outfitting basic design of ships and offshore vessels. Helping you deliver high-quality projects on time and on budget. Marine projects are challenging to deliver. Increasing size and complexity of vessels, short project lead times that require concurrent engineering and have unclear or changing specifications, and cost pressures that lead to globally distributed design and production running 24/7 require an ever-more sophisticated and aligned engineering approach. TM},
   title = {AVEVA E3D Design},
}
@misc{Agisoft,
   title = {Agisoft’s Popular PhotoScan Photogrammetry Tool Renamed “Metashape” – Techgage},
   url = {https://techgage.com/news/agisofts-photoscan-becomes-metashape/},
}
@misc{ReCap,
   title = {(190) Whats New in ReCap Pro 2022 - Scan to Mesh - YouTube},
   url = {https://www.youtube.com/watch?v=FtrkJU6RL44},
}
@misc{Carolaship,
   title = {SY Carola (point cloud) - Download Free 3D model by Scottish Maritime Museum (@ScottishMaritimeMuseum) [17bd818]},
   url = {https://sketchfab.com/3d-models/sy-carola-point-cloud-17bd8188447b48baab75125b9ad20788},
}
@article{balatti2023robot,
  title={Robot-Assisted Navigation for Visually Impaired through Adaptive Impedance and Path Planning},
  author={Balatti, Pietro and Ozdamar, Idil and Sirintuna, Doganay and Fortini, Luca and Leonori, Mattia and Gandarias, Juan M and Ajoudani, Arash},
  journal={arXiv preprint arXiv:2310.14705},
  year={2023}
}
@article{ngwenya2022virtual,
  title={Virtual obstacles for sensors incapacitation in robot navigation: A systematic review of 2D path planning},
  author={Ngwenya, Thabang and Ayomoh, Michael and Yadavalli, Sarma},
  journal={Sensors},
  volume={22},
  number={18},
  pages={6943},
  year={2022},
  publisher={MDPI}
}
@article{sun2023risk,
  title={Risk-Aware Deep Reinforcement Learning for Robot Crowd Navigation},
  author={Sun, Xueying and Zhang, Qiang and Wei, Yifei and Liu, Mingmin},
  journal={Electronics},
  volume={12},
  number={23},
  pages={4744},
  year={2023},
  publisher={MDPI}
}
@article{Bernhardt1994,
   abstract = {Tools for simulation and off-line programming became an important means for economic application of industrial robots. Until now the accuracy of simulation was not sufficiently precise for reliable down-load and execution of the off-line generated programs. A main cause for this was the controller specific motion behaviour of the robots that could not be simulated with sufficient accuracy. The RRS-project was created to overcome this deficite. By defining a suitable interface, it was made possible to integrate original controller software for motion behaviour into off-line programming systems.},
   author = {Rolf Bernhardt and Gerhard Schreck and Cornelius Willnow},
   doi = {10.1016/s1474-6670(17)46044-7},
   issn = {14746670},
   issue = {4},
   journal = {IFAC Proceedings Volumes},
   month = {6},
   pages = {321-324},
   publisher = {Elsevier BV},
   title = {The Realistic Robot Simulation (RRS) Interface},
   volume = {27},
   url = {https://robodk.com/blog/creating-realistic-virtual-environments-robot-simulation/},
   year = {1994},
}
@article{Shao2021,
   abstract = {The indoor robots are expected to complete metric navigation tasks safely and efficiently in complex environments, which is the essential prerequisite for accomplishing other high-level operation tasks. 2D occupancy grid maps are sufficient to support the robots in avoiding all obstacles in the environments during navigation. However, the maps based on normal laser scans only reflect a horizontal slice of the environment, which may cause the problem of some obstacles missing or misinterpreting their exact boundaries, thereby threatening the safety and efficiency of robot navigation. This paper presents a 2D mapping method based on virtual laser scans to provide a more comprehensive representation of obstacles for indoor robot navigation. The resulting maps can accurately represent the top-down projected contours of all obstacles no matter where their vertical positions are. The virtual laser scans are initially generated from raw data of an RGB-D camera based on the filtering, projection, and polar-coordinate scanning. The scans are fed directly to the laser-based simultaneous localization and mapping (SLAM) algorithms to update the current map and robot position. Two auxiliary strategies are proposed to further improve the quality of maps by reducing the impact of the narrow field of view and the blind zone of the RGB-D camera on the observations. In this paper, the improved virtual laser generation method makes the extracted 2D observations fit the laser-based SLAM algorithms, and two auxiliary strategies are novel ways to improve map quality. The generated maps can reflect the comprehensive obstacle information in indoor environments with good accuracy. The comparative experiments are carried out based on four simulation scenarios and three real-world scenarios to prove the effectiveness of our 2D mapping method.},
   author = {Xu-Yang Shao and Guo-Hui Tian and Ying Zhang},
   doi = {10.1007/s11633-021-1304-1},
   issn = {1751-8520},
   issue = {5},
   journal = {International Journal of Automation and Computing},
   pages = {747-765},
   title = {A 2D Mapping Method Based on Virtual Laser Scans for Indoor Robots},
   volume = {18},
   url = {https://doi.org/10.1007/s11633-021-1304-1},
   year = {2021},
}
@inproceedings{inproceedings,
author = {Rodić, Aleksandar and Mester, Gyula},
year = {2010},
month = {09},
pages = {115 - 120},
title = {Virtual WRSN — Modeling and Simulation of Wireless Robot-Sensor Networked Systems},
doi = {10.1109/SISY.2010.5647245}
}
@misc{Potentialfield,
   title = {(214) Leopoldo Armesto - YouTube},
   url = {https://www.youtube.com/@LeoArmesto},
}
@article{khatib1986real,
  title={Real-time obstacle avoidance for manipulators and mobile robots},
  author={Khatib, Oussama},
  journal={The international journal of robotics research},
  volume={5},
  number={1},
  pages={90--98},
  year={1986},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}
@misc{Pathplanning,
   title = {potential field path planning - Google Search},
   url = {https://www.google.com/search?sca_esv=f7d78de355298e03&sca_upv=1&q=potential+field+path+planning&tbm=vid&source=lnms&prmd=ivnbz&sa=X&ved=2ahUKEwj-8JjrkZyGAxUzlMMKHd9eD2gQ0pQJegQIERAB&biw=1474&bih=700&dpr=1.25#fpstate=ive&vld=cid:b7e3cee3,vid:3PYWezYama0,st:0},
}
@misc{path,
   title = {Path Planning Using Potential Field Algorithm | by Rymsha Siddiqui | Medium},
   url = {https://medium.com/@rymshasiddiqui/path-planning-using-potential-field-algorithm-a30ad12bdb08},
}
@article{lu2014information,
  title={An information potential approach to integrated sensor path planning and control},
  author={Lu, Wenjie and Zhang, Guoxian and Ferrari, Silvia},
  journal={IEEE Transactions on Robotics},
  volume={30},
  number={4},
  pages={919--934},
  year={2014},
  publisher={IEEE}
}
@misc{LocalMinimum,
   title = {(227) Motion Planning with Potential Fields | Mobile Robotics - YouTube},
   url = {https://www.youtube.com/watch?v=3PYWezYama0},
}
@misc{Cellhistogram,
   title = {(244) How to Implement VFH+ Algorithm using VFH+ Plugin | CoppeliaSim (V-REP) - YouTube},
   url = {https://www.youtube.com/watch?v=WMTEzHN7RIU&t=650s},
}
@article{Wang2018,
   author = {Zhongli Wang and Yan Chen and Yue Mei and Kuo Yang and Baigen Cai},
   doi = {10.3390/app8122534},
   journal = {Applied Sciences},
   month = {5},
   pages = {2534},
   title = {IMU-assisted 2D SLAM method for low-texture and dynamic environments},
   volume = {8},
   year = {2018},
}
@misc{PolarHistogram,
   title = {2d Polar Histogram - ROOT - ROOT Forum},
   url = {https://root-forum.cern.ch/t/2d-polar-histogram/22281/2},
}
@misc{VFH,
   title = {(245) Vector Field Histogram | Mobile Robotics - YouTube},
   url = {https://www.youtube.com/watch?v=X0nokJwoivQ},
}
@inproceedings{ulrich2000vfh,
  title={VFH/sup*: Local obstacle avoidance with look-ahead verification},
  author={Ulrich, Iwan and Borenstein, Johann},
  booktitle={Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No. 00CH37065)},
  volume={3},
  pages={2505--2511},
  year={2000},
  organization={IEEE}
}
@misc{VFH*,
   title = {(245) Vector Field Histogram | Mobile Robotics - YouTube},
   url = {https://www.youtube.com/watch?v=X0nokJwoivQ},
}
@article{Borenstein1991,
   abstract = {A new real-time obstacle avoidance method for mobile robots has been developed and implemented. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by on-board range sensors. The VFH method subsequently employs a two-stage data-reduction process in order to compute the desired control commands for the vehicle. In the first stage the histogram grid is reduced to a one-dimensional polar histogram that is constructed around the robot's momentary location. Each sector in the polar histogram contains a value representing the polar obstacle density in that direction. In the second stage, the algorithm selects the most suitable sector from among all polar histogram sectors with a low polar obstacle density, and the steering of the robot is aligned with that direction. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6 0.7m/sec demonstrate the power of the VFH method.},
   author = {by J Borenstein and Y Koren and Senior Member},
   issue = {3},
   journal = {IEEE Journal of Robotics and Automation},
   pages = {278-288},
   title = {THE VECTOR FIELD HISTOGRAM-FAST OBSTACLE AVOIDANCE FOR MOBILE ROBOTS},
   volume = {7},
   year = {1991},
}
@inproceedings{ulrich1998vfh+,
  title={VFH+: Reliable obstacle avoidance for fast mobile robots},
  author={Ulrich, Iwan and Borenstein, Johann},
  booktitle={Proceedings. 1998 IEEE international conference on robotics and automation (Cat. No. 98CH36146)},
  volume={2},
  pages={1572--1577},
  year={1998},
  organization={IEEE}
}
@misc{PF,
   title = {(260) How to Implement Potential Fields | CoppeliaSim (V-REP) - YouTube},
   url = {https://www.youtube.com/watch?v=zyIRKGgtyHs&list=PLjzuoBhdtaXOoqkJUqhYQletLLnJP8vjZ&index=64},
}
